{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Dataset - 223 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('./data/AAPL_preprocessed_data.py')\n",
    "\n",
    "# Drop 'time_stamp' column and reverse order\n",
    "timeseries = df.drop(columns=['time_stamp']).iloc[::-1]\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(timeseries) * 0.9)\n",
    "train, test = timeseries[:train_size], timeseries[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose scalar function\n",
    "def choose_scaler(columns, mm_features, ss_features):\n",
    "    for col in columns:\n",
    "        mean = train[col].mean()\n",
    "        std = train[col].std()\n",
    "        min_val, max_val = train[col].min(), train[col].max()\n",
    "\n",
    "        price_columns = ['open', 'high', 'low', 'close']\n",
    "        if col in price_columns:\n",
    "            ss_features.append(col)\n",
    "        elif min_val >= 0 and max_val <= 100: # Likely a bounded indicator, use minmax\n",
    "            mm_features.append(col)\n",
    "        elif abs(mean) < std: # Likely unbounded, use StandardScaler\n",
    "            ss_features.append(col)\n",
    "        else:\n",
    "            mm_features.append(col)\n",
    "\n",
    "        return mm_features, ss_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_features, ss_features = choose_scaler(train.columns, [], [])\n",
    "\n",
    "# Initialize scalers\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Scale features for training and testing\n",
    "train_scaled = train.copy()\n",
    "test_scaled = test.copy()\n",
    "\n",
    "# Apply MinMaxScaler to selected features\n",
    "for col in mm_features:\n",
    "    train_scaled[col] = min_max_scaler.fit_transform(train[[col]])\n",
    "    test_scaled[col] = min_max_scaler.transform(test[[col]])\n",
    "\n",
    "# Apply StandardScaler to selected features\n",
    "for col in ss_features:\n",
    "    train_scaled[col] = standard_scaler.fit_transform(train[[col]])\n",
    "    test_scaled[col] = standard_scaler.transform(test[[col]])\n",
    "\n",
    "\n",
    "train = train_scaled.values.astype('float32')\n",
    "test = test_scaled.values.astype('float32')\n",
    "\n",
    "# Create dataset\n",
    "def create_dataset(dataset, lookback, close_col):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset) - lookback):\n",
    "        feature = dataset[i: i + lookback]\n",
    "        target = dataset[i + lookback, close_col]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(np.array(X)), torch.tensor(np.array(y))\n",
    "\n",
    "\n",
    "lookback = 10\n",
    "close_col = df.columns.get_loc('close')\n",
    "X_train, y_train = create_dataset(train, lookback, close_col)\n",
    "X_test, y_test = create_dataset(test, lookback, close_col)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_layers, output_size, dropout_prob=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(num_features, hidden_dim, num_layers,\n",
    "                            batch_first=True, dropout=dropout_prob if num_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0),\n",
    "                         self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0),\n",
    "                         self.hidden_dim).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time step\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "num_features = X_train.shape[2]\n",
    "hidden_dim = 50\n",
    "num_layers = 1\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMModel(num_features, hidden_dim, num_layers, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# DataLoader\n",
    "loader = DataLoader(TensorDataset(X_train, y_train),\n",
    "                    shuffle=False, batch_size=8)\n",
    "\n",
    "# Train the model\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_batch = y_batch.view(-1, 1)  # Reshape target to [batch_size, 1]\n",
    "        y_pred = model(X_batch)  # Model output is [batch_size, 1]\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_train_pred = model(X_train)\n",
    "        y_train_actual = y_train.view(-1, 1)  # Reshape target to [batch_size, 1]\n",
    "        train_rmse = np.sqrt(loss_fn(y_train_pred, y_train_actual).item())\n",
    "\n",
    "        y_test_pred = model(X_test)\n",
    "        y_test_actual = y_test.view(-1, 1)  # Reshape target to [batch_size, 1]\n",
    "        test_rmse = np.sqrt(loss_fn(y_test_pred, y_test_actual).item())\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}/{epochs}, Train Loss: {train_rmse:.4f}, Test Loss: {test_rmse:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"complex_lstm_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    train_predictions = model(X_train)\n",
    "    test_predictions = model(X_test)\n",
    "\n",
    "    # Prepare plots\n",
    "    train_plot = np.full_like(timeseries[:, 0], np.nan)\n",
    "    test_plot = np.full_like(timeseries[:, 0], np.nan)\n",
    "\n",
    "    # Fill predictions in respective ranges\n",
    "    train_plot[lookback:train_size] = train_predictions.squeeze()\n",
    "    test_plot[train_size + lookback:] = test_predictions.squeeze()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(timeseries[:, close_col], label=\"Actual Close Price\", color=\"blue\")\n",
    "plt.plot(train_plot, label=\"Train Predictions\", color=\"red\")\n",
    "plt.plot(test_plot, label=\"Test Predictions\", color=\"green\")\n",
    "plt.legend()\n",
    "plt.title(\"Actual vs Predicted Close Prices\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Close Price\")\n",
    "plt.grid()\n",
    "plt.savefig(\"lstm_predictions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['open', 'high', 'low', 'close', 'volume', 'SMA_10', 'RMA_10' ,'ROC_10', 'RSI_14', 'RSX_14', 'EMA_10', 'DEMA_10', 'TEMA_10', 'WMA_10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'time_stamp' column and reverse order\n",
    "timeseries = df.drop(columns=['time_stamp']).iloc[::-1]\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(timeseries) * 0.9)\n",
    "train, test = timeseries[:train_size], timeseries[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scalers\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features for each scaler\n",
    "standard_scaler_features = ['open', 'high', 'low', 'close', \n",
    "                            'SMA_10', 'EMA_10', 'DEMA_10', 'TEMA_10', 'WMA_10']\n",
    "minmax_scaler_features = ['RSI_14', 'RSX_14', 'ROC_10', 'volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[standard_scaler_features] = standard_scaler.fit_transform(train[standard_scaler_features])\n",
    "train[minmax_scaler_features] = min_max_scaler.fit_transform(train[minmax_scaler_features])\n",
    "\n",
    "\n",
    "test[standard_scaler_features] = standard_scaler.transform(test[standard_scaler_features])\n",
    "test[minmax_scaler_features] = min_max_scaler.transform(test[minmax_scaler_features])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
